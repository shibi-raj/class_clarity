# The LLM model to use for processing emails
model: gemma3

# Maximum tokens to allow per prompt (for safety)
max_tokens: 1024

# Temperature controls randomness: 0 = deterministic, 1 = creative
temperature: 0.0

# Optional: stop sequences if you want to truncate output automatically
stop_sequences: ["\n\n"]

# Optional: role names or context defaults (can be overridden at runtime)
default_user_context: |
  I want my child to be well-rounded and excel in academics and sports.
  Provide deadlines, test dates, and special academic/sports events, try-out dates, concerts, etc.

default_output_context: |
  Return a bulleted, prioritized list of events with relevant dates.
  Include calendar-ready entries where possible.